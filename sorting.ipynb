{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mode\n",
    "import chiCa\n",
    "from spks import *\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workaround for having modified the kilosort clusters with Phy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clu = Clusters(folder = kilosort_path, get_waveforms=False)\n",
    "raw_data = RawRecording([fast_binary_path], return_preprocessed = False)\n",
    "clu.extract_waveforms(data = raw_data, save_folder_path = clu.folder) # no filtering if using filtered binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clu2 = Clusters(folder = kilosort_path, get_waveforms=True, load_template_features=True, get_metrics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_path = Path('/home/data/GRB006/20240429_174359/ephys_g0/ephys_g0_imec0/ephys_g0_t0.imec0.ap.bin')\n",
    "fast_binary_path = Path('/scratch/GRB/temp_bin/ephys_g0_t0.imec0.ap.bin')\n",
    "kilosort_path = Path('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading sync data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spks.sync import load_ni_sync_data,interp1d\n",
    "sessionpath = Path('/home/data/GRB006/20240429_174359/')\n",
    "sync_port = 0 # this is where the SMA of the probe is connected\n",
    "\n",
    "(nionsets,nioffsets),(nisync,nimeta),(apsyncdata) = load_ni_sync_data(sessionpath=sessionpath)\n",
    "aponsets = apsyncdata[0]['file0_sync_onsets'][6] # this should be the same for you, its where the sync is on the probe\n",
    "\n",
    "corrected_onsets = {} # This is a dictionary with the digital events that were connected to the breakout box.\n",
    "for k in nionsets.keys():\n",
    "    corrected_onsets[k] = interp1d(nionsets[sync_port],aponsets,fill_value='extrapolate')(nionsets[k]).astype('uint64')\n",
    "\n",
    "# if you need analog channels those are in \"nisync\"\n",
    "nitime = interp1d(nionsets[sync_port],aponsets,fill_value='extrapolate')(np.arange(len(nisync)))\n",
    "\n",
    "# everything is in samples, use this sampling rate\n",
    "srate = apsyncdata[0]['sampling_rate']  \n",
    "\n",
    "frame_rate = mode(1/(np.diff(corrected_onsets[1])/srate)) #corrected_onsets[1] are the frame samples, [2] are the trial start samples\n",
    "trial_start_times = corrected_onsets[2][:-1]/srate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/spks-gabriel/lib/python3.12/site-packages/chiCa/chipmunk_analysis_tools.py:321: UserWarning: Found multisensory trials, assumed synchronous condition\n",
      "  warnings.warn('Found multisensory trials, assumed synchronous condition')\n"
     ]
    }
   ],
   "source": [
    "behavior_data = chiCa.load_trialdata('/home/data/GRB006/20240429_174359/chipmunk/GRB006_20240429_174359_chipmunk_DemonstratorAudiTask.mat')\n",
    "\n",
    "# stim_period_times = np.zeros(shape=(len(behavior_data),1))\n",
    "# relative_stim_period_times = np.zeros(shape=(len(behavior_data),1))\n",
    "\n",
    "# for trial, _ in behavior_data.PlayStimulus.items(): #unpacking index as trial and omitting the data\n",
    "#     stim_period_times[trial] = behavior_data.trial_start_time[trial] + behavior_data.PlayStimulus[trial][0]\n",
    "#     relative_stim_period_times[trial] = behavior_data.PlayStimulus[trial][0]\n",
    "\n",
    "\n",
    "# stim_period_times = stim_period_times.flatten()\n",
    "# relative_stim_period_times = relative_stim_period_times.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get stimulus onsets aligned to nidaq time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not exactly aligned to hybrid time as it's trial start (nidaq) + stimulus timestamps (Bpod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_onsets = trial_start_times + behavior_data.stimulus_event_timestamps\n",
    "\n",
    "first_stim_onsets = np.zeros(len(stim_onsets))\n",
    "for trial, timestamps in enumerate(stim_onsets):\n",
    "    if np.isnan(timestamps[0]):\n",
    "        first_stim_onsets[trial] = np.nan\n",
    "    else:\n",
    "        first_stim_onsets[trial] = timestamps[0]\n",
    "\n",
    "first_stim_onsets = first_stim_onsets[~np.isnan(first_stim_onsets)]\n",
    "# first_stim_onsets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying that it worked..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(stim_onsets[:5]), 1, figsize=(5,5))\n",
    "for i, trials in enumerate(stim_onsets[:5]):\n",
    "    axs[i].vlines(stim_onsets[i], 0, 1)\n",
    "    axs[i].get_yaxis().set_visible(False)\n",
    "axs[-1].set_xlabel('Stimulus timestamps (s)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temp ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_analog = nisync[:, 0]\n",
    "threshold = 10000\n",
    "stim_digital = (stim_analog > threshold).astype(int)\n",
    "\n",
    "t = nitime/srate\n",
    "idx = t<20 #first # of seconds of the session\n",
    "fig, axs = plt.subplots(1,2, figsize=(14,8))\n",
    "axs[0].plot(t[idx],stim_digital[idx],'k')\n",
    "axs[0].set_xlim([15.1, 16.1])\n",
    "\n",
    "# t = nitime/srate\n",
    "# idx = t<300 #first # of seconds of the session\n",
    "# fig = plt.figure()\n",
    "axs[1].plot(t[idx],nisync[idx,0],'k')\n",
    "axs[1].set_xlim([15.1, 16.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxcar_signal(stim_digital, min_event_gap=30):  # gap in samples\n",
    "    transitions = np.diff(stim_digital)\n",
    "    start_indices = np.where(transitions == 1)[0] + 1\n",
    "    end_indices = np.where(transitions == -1)[0] + 1\n",
    "\n",
    "    if stim_digital[0] == 1:\n",
    "        start_indices = np.insert(start_indices, 0, 0)\n",
    "    if stim_digital[-1] == 1:\n",
    "        end_indices = np.append(end_indices, len(stim_digital))\n",
    "\n",
    "    # Consolidate closely spaced mini-events\n",
    "    consolidated_starts = []\n",
    "    consolidated_ends = []\n",
    "    current_start = start_indices[0]\n",
    "    for i in range(1, len(start_indices)):\n",
    "        if start_indices[i] - end_indices[i - 1] > min_event_gap:\n",
    "            consolidated_starts.append(current_start)\n",
    "            consolidated_ends.append(end_indices[i - 1])\n",
    "            current_start = start_indices[i]\n",
    "    consolidated_starts.append(current_start)\n",
    "    consolidated_ends.append(end_indices[-1])\n",
    "\n",
    "    boxcar_signal = np.zeros_like(stim_digital)\n",
    "    for start, end in zip(consolidated_starts, consolidated_ends):\n",
    "        boxcar_signal[start:end] = 1\n",
    "\n",
    "    return boxcar_signal\n",
    "\n",
    "# Generate the boxcar signal\n",
    "boxcar_signal = get_boxcar_signal(stim_digital)\n",
    "\n",
    "# Plot the original and boxcar signals\n",
    "t = nitime/srate\n",
    "idx = t < 300  # First 20 seconds of the session\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# Original digital signal in the specified range\n",
    "axs[0].plot(t[idx], boxcar_signal[idx], 'k')\n",
    "# axs[0].set_xlim([15, 16.2])\n",
    "axs[0].set_ylim([-0.5, 1.5])\n",
    "axs[0].set_title('Original Digital Signal')\n",
    "axs[0].set_xlabel('Time (s)')\n",
    "axs[0].set_ylabel('Signal')\n",
    "\n",
    "# Analog signal in the specified range\n",
    "axs[1].plot(t[idx], nisync[idx, 0], 'k')\n",
    "# axs[1].set_xlim([15, 16.2])\n",
    "axs[1].set_title('Analog Signal')\n",
    "axs[1].set_xlabel('Time (s)')\n",
    "axs[1].set_ylabel('Signal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nitime/srate\n",
    "t = ~np.isnan(t)\n",
    "boxcar_signal[t].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_event_idx = np.where(boxcar_signal == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_event_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = trial_start_samples[0]\n",
    "end_idx = trial_start_samples[0 + 1]\n",
    "stim_event_idx[(stim_event_idx >= start_idx) & (stim_event_idx < end_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_event_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few values of trial_start_samples and stim_event_idx\n",
    "print(\"First 10 trial_start_samples:\", trial_start_samples[:10])\n",
    "print(\"First 10 stim_event_idx:\", stim_event_idx[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to align stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_alignment_data = chiCa.align_behavioral_video('/home/data/GRB006/20240429_174359/chipmunk/GRB006_20240429_174359_chipmunk_DemonstratorAudiTask_BackStereoView_00000000.camlog') #this has the trial start frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so I have trial start frames for behavior in trial_start_frames\n",
    "# trial_start_frames = video_alignment_data['trial_starts']\n",
    "\n",
    "# I have trial start frames for npx in corrected_onsets[2]\n",
    "trial_start_samples = corrected_onsets[2][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = np.load('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/spike_clusters.npy') # vector of all spike times recorded\n",
    "st = np.load('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/spike_times.npy') # vector of to what cluster each spike belonged to\n",
    "\n",
    "assert sc.shape == st.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labcams\n",
    "\n",
    "logdata, comments = labcams.parse_cam_log('/home/data/GRB006/20240429_174359/chipmunk/GRB006_20240429_174359_chipmunk_DemonstratorAudiTask_BackStereoView_00000000.camlog')\n",
    "\n",
    "# (logdata.timestamp.values[-1]-logdata.timestamp.values[0])/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bpodtime = interp1d(nionsets[sync_port],corrected_onsets[2],fill_value='extrapolate')(np.arange(len(nisync)))\n",
    "bpodtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSTHs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = np.load('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/spike_clusters.npy')\n",
    "# st = np.load('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/spike_times.npy')\n",
    "\n",
    "# if sc.shape != st.shape:\n",
    "#     raise ValueError(f\"The shapes of sc {sc.shape} and st {st.shape} are not the same\")\n",
    "\n",
    "# df = pd.DataFrame({'spike_samples': st, 'spike_clusters': sc})\n",
    "# df['spike_times'] = df['spike_samples'] / srate\n",
    "# cluster_spike_times = df.groupby('spike_clusters').agg(spike_samples=('spike_samples', list), spike_times=('spike_times', list)).reset_index()\n",
    "\n",
    "# cluster_spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp_samples = np.array(cluster_spike_times.spike_samples[7])\n",
    "# start = trial_start_samples[0]\n",
    "# end = trial_start_samples[1]\n",
    "\n",
    "# filtered_sp_samples = sp_samples[(sp_samples >= start) & (sp_samples <= end)]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.eventplot(filtered_sp_samples, lineoffsets=0.5, colors='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_path = Path('/home/data/GRB006/20240429_174359/ephys_g0/ephys_g0_imec0/ephys_g0_t0.imec0.ap.bin')\n",
    "# fast_binary_path = Path('/scratch/GRB/temp_bin/ephys_g0_t0.imec0.ap.bin')\n",
    "kilosort_path = Path('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/')\n",
    "\n",
    "clu = Clusters(folder = kilosort_path, get_waveforms=False, get_metrics=True, load_template_features=True)\n",
    "\n",
    "# ---------- this gets the row indices ---------- #\n",
    "single_unit_idx = np.where((np.abs(clu.cluster_info.trough_amplitude - clu.cluster_info.peak_amplitude) > 50)\n",
    "            & (clu.cluster_info.amplitude_cutoff < 0.1) \n",
    "            & (clu.cluster_info.isi_contamination < 0.1)\n",
    "            & (clu.cluster_info.presence_ratio >= 0.6)\n",
    "            & (clu.cluster_info.spike_duration > 0.1))[0]\n",
    "\n",
    "# ---------- and this get the cluster_id values ---------- #\n",
    "mask = ((np.abs(clu.cluster_info.trough_amplitude - clu.cluster_info.peak_amplitude) > 50)\n",
    "            & (clu.cluster_info.amplitude_cutoff < 0.1) \n",
    "            & (clu.cluster_info.isi_contamination < 0.1)\n",
    "            & (clu.cluster_info.presence_ratio >= 0.6)\n",
    "            & (clu.cluster_info.spike_duration > 0.1))\n",
    "\n",
    "\n",
    "single_unit_ids = clu.cluster_info[mask].cluster_id.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code from tutorial\n",
    "https://github.com/jcouto/cshl_spks/blob/main/tutorials/tutorial_plot_psths.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = np.load('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/spike_clusters.npy')\n",
    "ss = np.load('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/spike_times.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(st[selection])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = ss/srate\n",
    "# trial_start_times = trial_start_samples/srate\n",
    "\n",
    "# lets plot a population PSTH of good units\n",
    "# lets do this only for good units\n",
    "selection = np.isin(sc,single_unit_ids)\n",
    "\n",
    "binsize = 0.01 # lets use a 10ms binsize\n",
    "edges = np.arange(0,np.max(st[selection]),binsize)\n",
    "\n",
    "pop_rate,_ = np.histogram(st[selection],edges)\n",
    "pop_rate = pop_rate/binsize\n",
    "pop_rate_time = edges[:-1]+np.diff(edges[:2])/2\n",
    "\n",
    "psth = []\n",
    "tpre = 0.5\n",
    "tpost = 1\n",
    " \n",
    "for onset in first_stim_onsets:\n",
    "    psth.append(pop_rate[(pop_rate_time>= onset -tpre) & (pop_rate_time< onset +tpost)])\n",
    "psth = np.stack(psth)\n",
    "fig1 = plt.figure(figsize=(10,10))\n",
    "plt.imshow(psth,aspect='auto',extent=[-tpre,tpost,0,len(psth)],cmap = 'RdBu_r',clim = [0,2500])\n",
    "plt.colorbar(label='Population rate (Hz)')\n",
    "plt.xlabel('time from first stim event')\n",
    "plt.ylabel('Number of trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clus = sc[selection]\n",
    "# separate the spikes from each unit\n",
    "timestamps = [st[selection][clus == uclu] for uclu in np.unique(clus)]\n",
    "\n",
    "trig_ts = []\n",
    "for sp in timestamps:\n",
    "    trig_ts.append([])\n",
    "    for o in first_stim_onsets:\n",
    "        trig_ts[-1].append(sp[(sp>=(o-tpre)) & (sp<(o+tpost))] - o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "fig2, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "tpre = 0.1\n",
    "tpost = 1\n",
    "\n",
    "@interact(iunit=IntSlider(min=0, max=len(trig_ts)-1, step=1, value=0))\n",
    "def g(iunit):\n",
    "    # ax.clear()\n",
    "    plt.clf()\n",
    "    iunit = iunit\n",
    "    for i,ss in enumerate(trig_ts[iunit]):\n",
    "        plt.vlines(ss,i,i+1,color = 'k')\n",
    "    plt.xlim([-tpre,tpost])\n",
    "    # plt.ylim([0,len(stimlog)])\n",
    "    plt.ylabel('Trial #')\n",
    "    plt.xlabel('Time from first stim onset (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interesting units to plot\n",
    "#excitation: 67, 28, 29, 32, 105, 136, 151, 154, 209, 216\n",
    "#inhibition: 4, 82, 84, 67, 82, 99, 106, 162, 166, 167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntSlider, Button, HBox, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_individual_neurons_interactively(trig_ts, tpre=0.1, tpost=1):\n",
    "    # Create the figure and axis\n",
    "    fig2, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "    # Define the plotting function\n",
    "    def plot_neuron(iunit):\n",
    "        ax.clear()\n",
    "        for i, ss in enumerate(trig_ts[iunit]):\n",
    "            ax.vlines(ss, i, i + 1, color='k')\n",
    "        ax.set_xlim([-tpre, tpost])\n",
    "        ax.set_ylabel('Trial #')\n",
    "        ax.set_xlabel('Time from first stim onset (s)')\n",
    "        fig2.canvas.draw_idle()  # Update the plot without blocking\n",
    "\n",
    "    # Create the slider and buttons\n",
    "    slider = IntSlider(min=0, max=len(trig_ts) - 1, step=1, value=0)\n",
    "    next_button = Button(description=\"Next\")\n",
    "    prev_button = Button(description=\"Previous\")\n",
    "\n",
    "    # Define button click event handlers\n",
    "    def on_next_button_clicked(b):\n",
    "        slider.value = min(slider.value + 1, slider.max)\n",
    "\n",
    "    def on_prev_button_clicked(b):\n",
    "        slider.value = max(slider.value - 1, slider.min)\n",
    "\n",
    "    # Attach event handlers to buttons\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "\n",
    "    # Update plot when slider value changes\n",
    "    def on_slider_value_change(change):\n",
    "        plot_neuron(change['new'])\n",
    "\n",
    "    slider.observe(on_slider_value_change, names='value')\n",
    "\n",
    "    # Display buttons and slider\n",
    "    display(VBox([HBox([prev_button, next_button]), slider]))\n",
    "\n",
    "    # Initial plot\n",
    "    plot_neuron(slider.value)\n",
    "\n",
    "plot_individual_neurons_interactively(trig_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ss in enumerate(trig_ts[iunit]):\n",
    "    ax.vlines(ss, i, i + 1, color='k')\n",
    "ax.set_xlim([-tpre, tpost])\n",
    "ax.set_ylabel('Trial #')\n",
    "ax.set_xlabel('Time from first stim onset (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trig_ts[151][37].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compute the psth, now it is a bit more tricky \n",
    "# because we don't have equal number of opto and no-opto trials\n",
    "# we just have to do it per trial\n",
    "nunits,ntrials,nstims,ntime = trig_unit_rates_ori.shape\n",
    "psth_mean = np.zeros([nunits,2,nstims,ntime]) # one for opto and one for no-opto\n",
    "psth_sterr = np.zeros([nunits,2,nstims,ntime]) \n",
    "for istim in range(nstims):\n",
    "    optoidx = np.sort(has_opto[istim])\n",
    "    for sel in [0,1]: # select between no_opto and opto trials\n",
    "        psth_mean[:,sel,istim] = trig_unit_rates_ori[:,optoidx==sel,istim].mean(axis = 1)\n",
    "        psth_sterr[:,sel,istim] = trig_unit_rates_ori[:,optoidx==sel,istim].std(axis = 1)/np.sqrt(np.sum(optoidx==sel))\n",
    "\n",
    "# Plot the single trials\n",
    "iunit = 21\n",
    "plt.figure()\n",
    "t = np.linspace(-tpre,tpost,psth_mean.shape[-1])\n",
    "plt.plot(t,psth_mean[iunit,0].T,color = 'k',alpha = 0.5)\n",
    "plt.plot(t,psth_mean[iunit,1].T,color = 'blue',alpha = 0.5)\n",
    "# plot the visual stim dur (we are using the arduino, there is a 60ms (measured) lag)\n",
    "plt.plot([0.060,0.060+1],np.array([1,1])*np.max(plt.ylim())*0.9,\n",
    "         lw = 5,color='lightgray')\n",
    "plt.plot([0.5,0.5+1],np.array([1,1])*np.max(plt.ylim())*0.95,\n",
    "         lw = 5,color='blue')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('spks/sec');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sandbox - ignore for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_times = np.array(cluster_spike_times.spike_times[7])\n",
    "# sp_times[sp_times>300]\n",
    "\n",
    "# Define the time window\n",
    "start_time = 0  # Start of the time window\n",
    "end_time = 10    # End of the time window\n",
    "\n",
    "# Filter the spike times to include only those within the time window\n",
    "filtered_sp_times = sp_times[(sp_times >= start_time) & (sp_times <= end_time)]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.eventplot(filtered_sp_times, lineoffsets=0.5, colors='black')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_units_df = clu.cluster_info[\n",
    "    (np.abs(clu.cluster_info.trough_amplitude - clu.cluster_info.peak_amplitude) > 50) \n",
    "    & (clu.cluster_info.amplitude_cutoff < 0.1) \n",
    "    & (clu.cluster_info.isi_contamination < 0.1)\n",
    "    & (clu.cluster_info.presence_ratio >= 0.6)\n",
    "    & (clu.cluster_info.spike_duration > 0.1)\n",
    "]\n",
    "\n",
    "single_units_df.cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_info_histograms(clu):\n",
    "    # Setup\n",
    "    fig, axs = plt.subplots(3, 2, tight_layout=True, figsize=(10, 6))\n",
    "    n_bins = 50\n",
    "\n",
    "    # Calculate the total number of neurons\n",
    "    total_neurons = len(clu.cluster_info)\n",
    "\n",
    "    # Calculate the excluded samples\n",
    "    excluded_peak_amplitude = np.sum(np.abs(clu.cluster_info.trough_amplitude - clu.cluster_info.peak_amplitude) <= 50)\n",
    "    excluded_isi_contamination = np.sum(clu.cluster_info.isi_contamination > 0.1)\n",
    "    excluded_spike_duration = np.sum(clu.cluster_info.spike_duration <= 0.1)\n",
    "    excluded_presence_ratio = np.sum(clu.cluster_info.presence_ratio <= 0.6)\n",
    "    excluded_amplitude_cutoff = np.sum(clu.cluster_info.amplitude_cutoff > 0.1)\n",
    "\n",
    "    # Set the figure title\n",
    "    fig.suptitle(f'Total clusters: {total_neurons}\\n Shaded area indicates excluded clusters by metric', fontsize=14)\n",
    "\n",
    "    # ------- Plot histograms ------- #\n",
    "\n",
    "    # spike amplitude\n",
    "    axs[0, 0].hist(np.abs(clu.cluster_info.trough_amplitude - clu.cluster_info.peak_amplitude), bins=n_bins, alpha=0.5, color='b')\n",
    "    axs[0, 0].axvline(x=50, color='b', linestyle='--')\n",
    "    axs[0, 0].fill_betweenx(y=axs[0, 0].get_ylim(), x1=max(axs[0, 0].get_xlim()[0], 0), x2=50, color='b', alpha=0.1)\n",
    "    axs[0, 0].set_xlabel('spike amplitude')\n",
    "    axs[0, 0].set_ylabel('counts')\n",
    "    axs[0, 0].set_title(f'n = {excluded_peak_amplitude}')\n",
    "\n",
    "    # ISI contamination\n",
    "    axs[1, 0].hist(clu.cluster_info.isi_contamination, bins=n_bins, alpha=0.5, color='g')\n",
    "    axs[1, 0].axvline(x=0.1, color='g', linestyle='--')\n",
    "    axs[1, 0].fill_betweenx(y=axs[1, 0].get_ylim(), x1=0.1, x2=min(axs[1, 0].get_xlim()[1], axs[1, 0].get_xlim()[1]), color='g', alpha=0.1)\n",
    "    axs[1, 0].set_xlabel('isi_contamination')\n",
    "    axs[1, 0].set_ylabel('counts')\n",
    "    axs[1, 0].set_title(f'n = {excluded_isi_contamination}')\n",
    "\n",
    "    # spike duration\n",
    "    axs[2, 0].hist(clu.cluster_info.spike_duration, bins=n_bins, alpha=0.5, color='r')\n",
    "    axs[2, 0].axvline(x=0.1, color='r', linestyle='--')\n",
    "    axs[2, 0].fill_betweenx(y=axs[2, 0].get_ylim(), x1=max(axs[2, 0].get_xlim()[0], 0), x2=0.1, color='r', alpha=0.1)\n",
    "    axs[2, 0].set_xlabel('spike_duration')\n",
    "    axs[2, 0].set_ylabel('counts')\n",
    "    axs[2, 0].set_title(f'n = {excluded_spike_duration}')\n",
    "\n",
    "    # presence ratio\n",
    "    axs[0, 1].hist(clu.cluster_info.presence_ratio, bins=n_bins, alpha=0.5, color='orange')\n",
    "    axs[0, 1].axvline(x=0.6, color='orange', linestyle='--')\n",
    "    axs[0, 1].fill_betweenx(y=axs[0, 1].get_ylim(), x1=max(axs[0, 1].get_xlim()[0], 0), x2=0.6, color='orange', alpha=0.1)\n",
    "    axs[0, 1].set_xlabel('presence_ratio')\n",
    "    axs[0, 1].set_ylabel('counts')\n",
    "    axs[0, 1].set_title(f'n = {excluded_presence_ratio}')\n",
    "\n",
    "    # amplitude cutoff\n",
    "    axs[1, 1].hist(clu.cluster_info.amplitude_cutoff, bins=n_bins, alpha=0.5, color='purple')\n",
    "    axs[1, 1].axvline(x=0.1, color='purple', linestyle='--')\n",
    "    axs[1, 1].fill_betweenx(y=axs[1, 1].get_ylim(), x1=0.1, x2=min(axs[1, 1].get_xlim()[1], axs[1, 1].get_xlim()[1]), color='purple', alpha=0.1)\n",
    "    axs[1, 1].set_xlabel('amplitude_cutoff')\n",
    "    axs[1, 1].set_ylabel('counts')\n",
    "    axs[1, 1].set_title(f'n = {excluded_amplitude_cutoff}')\n",
    "\n",
    "    # depth - not used for filtering out clusters, but a helpful viz nonetheless\n",
    "    axs[2, 1].hist(clu.cluster_info.depth, bins=n_bins, alpha=0.5, color='c')\n",
    "    axs[2, 1].set_xlabel('depth')\n",
    "    axs[2, 1].set_ylabel('counts')\n",
    "\n",
    "\n",
    "plot_cluster_info_histograms(clu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_spiketimes = clu.spike_times[np.isin(clu.spike_clusters,single_unit_idx)] \n",
    "units_spikeclusters = clu.spike_clusters[np.isin(clu.spike_clusters,single_unit_idx)]  \n",
    "\n",
    "assert units_spiketimes.shape == units_spikeclusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLUSTER_ID = 9\n",
    "# good_spikes = good_spikes[good_clusters == CLUSTER_ID] # only get spikes from one cluster\n",
    "# print(f'We will extract {len(good_spikes)} spikes for this cluster')\n",
    "\n",
    "# # good_spikes = np.hstack((good_spikes + 30000, good_spikes + np.max(good_spikes) - 30000))\n",
    "# print(good_spikes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spks.waveforms as spwaves\n",
    "\n",
    "# SCRATCH_DIR = '/scratch/GRB' # fast disk to write memmap file\n",
    "# nchannels = raw_data.shape[1]\n",
    "\n",
    "# waves = spwaves.extract_memmapped_waveforms(raw_data, SCRATCH_DIR, good_spikes[:100])\n",
    "# waves.shape # (nspikes, nsamples, nchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_times = read_phy_data(kilosort_path, srate=1, use_kilosort_results=True)['ts'] #ts = timestamps i think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu.load_waveforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waves = load_dict_from_h5('/home/data/GRB006/20240429_174359/kilosort2.5/imec0/cluster_waveforms.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waves.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_waves = [waves[i] for i in single_unit_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_waves[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_idx = raw_data.metadata[0]['channel_idx']\n",
    "np.mean(units_waves[0][:,:,383], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spks.phy_utils import read_phy_data\n",
    "from spks.waveforms import extract_waveform_set\n",
    "\n",
    "# spike_times = read_phy_data(kilosort_path, srate=1, use_kilosort_results=True)['ts'] #ts = timestamps i think\n",
    "SCRATCH_DIR = '/scratch/GRB/temp_waves' # fast disk to write memmap file\n",
    "nchannels = raw_data.shape[1]\n",
    "\n",
    "# waves = extract_waveform_set(spike_times, raw_data, max_n_spikes=100)\n",
    "# st = [spike_times[i] for i in single_unit_idx[single_unit_idx!=1084]]\n",
    "waves = extract_waveform_set(units_spiketimes, raw_data, max_n_spikes=100, mmap_output=True, scratch_directory=SCRATCH_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "from spks.viz import plot_footprints\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "\n",
    "@interact(clu_ids=IntSlider(min=0, max=len(units_waves)-1, step=1, value=0))\n",
    "def g(clu_ids):\n",
    "    ax.clear()\n",
    "\n",
    "    channel_xy = raw_data.metadata[0]['coords']\n",
    "    channel_idx = raw_data.metadata[0]['channel_idx']-1\n",
    "    plot_footprints(np.mean(units_waves[clu_ids][:,:,channel_idx], axis=0), channel_xy, shade_color='k')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird clusters: 48, 79, 81, 83, 90, 91, 113, 115... there's actually a bunch of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_unit_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,5])\n",
    "# plot the cluster waveforms accross all channels and overlay with the standard deviation\n",
    "plot_footprints(clu.cluster_waveforms_mean[clu.cluster_id == 9],clu.channel_positions,\n",
    "                shade_data = clu.cluster_waveforms_std[clu.cluster_id == 9].squeeze(), color='r');\n",
    "# plt.axis((720, 805., 1407, 1677));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the principal channels for a set of clusters\n",
    "# %matplotlib notebook\n",
    "# plot some of the high amplitude clusters\n",
    "clusters = clu.cluster_id[np.argsort(clu.trough_amplitude)[:5]]\n",
    "for iclu,c in zip(clusters,['#d62728',\n",
    "                            '#1f77b4',\n",
    "                            '#ff7f0e',\n",
    "                            '#2ca02c',\n",
    "                            '#9467bd']):\n",
    "    \n",
    "    idx = clu.active_channels[clu.cluster_id == iclu][0]\n",
    "    plot_footprints(clu.cluster_waveforms_mean[clu.cluster_id == iclu].squeeze()[:,idx],clu.channel_positions[idx,:],\n",
    "                    color=c);\n",
    "    \n",
    "# plt.axis((718, 808, 1718, 2231));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
