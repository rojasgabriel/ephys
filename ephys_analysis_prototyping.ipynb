{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "new_rc_params = {'text.usetex': False,\n",
    "\"svg.fonttype\": 'none'\n",
    "}\n",
    "mpl.rcParams.update(new_rc_params)\n",
    "plt.rcParams['font.sans-serif'] = ['Arial'] \n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "import chiCa.chiCa as chiCa\n",
    "from chiCa.chiCa.visualization_utils import separate_axes\n",
    "import spks\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading raw nidaq and behavior data and preprocessing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading nisync data...\n",
      "Success!\n",
      "-----\n",
      "Loading nidaq events...\n",
      "Port events found. Proceeding with extracting them...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabriel/lib/chiCa/chiCa/chipmunk_analysis_tools.py:321: UserWarning: Found multisensory trials, assumed synchronous condition\n",
      "  warnings.warn('Found multisensory trials, assumed synchronous condition')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "from utils import load_sync_data, process_port_events, process_trial_data\n",
    "\n",
    "animal = 'GRB006'\n",
    "session = '20240723_142451'\n",
    "sessionpath = Path(f'/Volumes/T7/{session}')\n",
    "\n",
    "corrected_onsets, corrected_offsets, t, srate, analog_signal = load_sync_data(sessionpath)\n",
    "trial_starts, port_events = process_port_events(corrected_onsets, corrected_offsets, srate)\n",
    "behavior_data, trial_ts = process_trial_data(sessionpath, trial_starts, t, srate, analog_signal, port_events, animal, session)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and filtering KS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# good units: 178\n"
     ]
    }
   ],
   "source": [
    "from utils import get_good_units, get_cluster_spike_times\n",
    "\n",
    "kilosort_path = Path(f'{sessionpath}/kilosort2.5/imec0/')\n",
    "sc = np.load(pjoin(kilosort_path, 'spike_clusters.npy')) #KS clusters\n",
    "ss = np.load(pjoin(kilosort_path, 'spike_times.npy')) #KS spikes (in samples)\n",
    "st = ss/srate #conversion from spike samples to spike times\n",
    "\n",
    "clu =  spks.clusters.Clusters(folder = kilosort_path, get_waveforms=False, get_metrics=True, load_template_features=True)\n",
    "\n",
    "good_units_mask, n_units = get_good_units(clusters_obj = clu, spike_clusters = sc)\n",
    "print(f'# good units: {n_units}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving preprocessed neural and behavioral data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('processed_data') / animal / session\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Convert to object array before saving\n",
    "spike_times_per_unit = get_cluster_spike_times(spike_times = st, spike_clusters = sc, good_unit_ids = good_units_mask)\n",
    "spike_times_array = np.array(spike_times_per_unit, dtype=object)\n",
    "\n",
    "# Save spike times and trial data\n",
    "np.save(save_dir / 'spike_times_per_unit.npy', spike_times_array, allow_pickle=True)\n",
    "trial_ts.to_pickle(save_dir / 'trial_ts.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data for one session locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('processed_data')\n",
    "animal = 'GRB006'  # example animal\n",
    "session = '20240723_142451'  # example session\n",
    "\n",
    "data_dir = save_dir / animal / session\n",
    "trial_ts = pd.read_pickle(data_dir / 'trial_ts.pkl')\n",
    "spike_times_per_unit = np.load(data_dir / 'spike_times_per_unit.npy', allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
